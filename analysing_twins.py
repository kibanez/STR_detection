"""
Created on 21/06/2018

@author: kristina ibanez-garikano

It takes a tsv file including IIDs of twins
It checks across all the loci, and compares the repeat-size estimations
"""


# !/usr/bin/python

import sys
import os
import re
import optparse
from os import path as osp
import pandas as pd
import logging
import vcf
from operator import itemgetter

localModulesBase = osp.dirname(osp.realpath(__file__))

modulesRelDirs = ["../modules/"]

for moduleRelDir in modulesRelDirs:
    sys.path.insert(0, osp.join(localModulesBase, moduleRelDir))


class OptionParser(optparse.OptionParser):
    def check_required(self, opt):

        option = self.get_option(opt)

        atrib = getattr(self.values, option.dest)

        if atrib is None:
            #            self.error("%s option not supplied" % option)
            return False
        else:
            return True


def print_tables(hash_table, f_output):
    """
    Function that prints the outcome of analysing twin's EH output VCF files

    :param hash_table: it contains the frequencies for each locus
    :param f_output: file in where the function will write the info in hash_table
    :return: a TSV output file
    """

    l_fields = ['gene', 't1_name', 't2_name', 't1_alt1', 't2_alt1', 'diff_a1', 't1_alt2', 't2_alt2', 'diff_a2']

    fo = open(f_output, 'w')
    fo.write('\t'.join(l_fields) + '\n')
    for key in sorted(hash_table.keys()):
        fo.write('\t'.join(map(lambda field: hash_table[key].get(field, '.'), l_fields)) + '\n')
    fo.close()

    return f_output

def read_tsv_file(input_tsv):

    """
    It reads a TSV file containing the list of twins we need to analyse
    :param input_tsv: tsv file with 4 columns: FamilyID\tParticipantID1\tIID1\tParticipantID2\tIID2
    :return: hash table containing the 2 columns - associates the LP id of Twin1 with the LP id of Twin2
    """

    data = pd.read_csv(input_tsv, sep="\t", header=None)

    l_twin1 = data.iloc[:, 2].tolist()
    l_twin2 = data.iloc[:, 4].tolist()

    hash_table = dict(zip(l_twin1, l_twin2))

    return hash_table

def analysing_VCFs(hash_twins,l_samples, eh_folder, logger):

    """

    :param hash_twins: hash table with the correspondance between twin1 and twin2 LPs
    :param l_samples: list of VCF we do have in the folder with the EH output VCF files
    :param eh_folder: directory where EH VCF output files are located
    :param logger: logger
    :return: hash table including `locus - twin1_a1 - twin2_a1 - diff_a1 - twin1_a2 - twin2_a2 - diff_a2`
    """

    hash_table = {}

    # We only analyse those cases for which we do have genomes for both twins

    for key in hash_twins:

        # First we need to check whether the EH output VCF files corresponding to both twins do exist
        if (key in l_samples) and (hash_twins[key] in l_samples):

            twin1_vcf = os.path.join(eh_folder, 'EH_' + key + '.vcf')
            twin2_vcf = os.path.join(eh_folder, 'EH_' + hash_twins[key] + '.vcf')

            twin1_name = key
            twin2_name = hash_twins[key]

            if not os.path.isfile(twin1_vcf):
                raise IOError("The VCF file corresponding to twin1 does not exist %s ") % twin1_vcf

            if not os.path.isfile(twin2_vcf):
                raise IOError("The VCF file corresponding to twin2 does not exist %s ") % twin2_vcf

            # Sometimes the VCF generated by EH is empty. We need to check whether the VCF is empty or not
            if (os.path.getsize(twin1_vcf) == 0) or (os.path.getsize(twin2_vcf) == 0):
                print twin1_vcf + twin2_vcf + '\n'
                continue

            vcf_reader1 = vcf.Reader(filename=twin1_vcf)
            vcf_reader2 = vcf.Reader(filename=twin2_vcf)

            # Reading and analysing twin-VCF1
            for i, r in enumerate(vcf_reader1):

                try:

                    hash_fields = dict(r.INFO)
                    
                    hash_fields.update(dict(zip(r.samples[0].data._fields, r.samples[0].data)))

                    # We only analyse STR markers >=3 length
                    if len(str(hash_fields.get('RU', 0))) >= 3:

                        gene = str(hash_fields.get('REPID', ""))

                        # we retrieve all the info contained in the INFO fields
                        hash_variant = {}

                        hash_variant['t1_alt1'] = str(hash_fields.get('REPCN', 0)).split('/')[0]
                        hash_variant['t1_alt2'] = str(hash_fields.get('REPCN', 0)).split('/')[1]
                        hash_variant['t1_name'] = twin1_name
                        hash_variant['gene'] = gene
                        hash_variant['t2_alt1'] = '0'
                        hash_variant['t2_alt2'] = '0'
                        hash_variant['t2_name'] = twin2_name
                        hash_table[(twin1_name, twin2_name, gene)] = hash_variant

                except:

                    raise RuntimeError(
                        'analysing_VCFs: Some error has occurred in variant line')

            # Reading and analysing twin-VCF2
            for i, r in enumerate(vcf_reader2):

                try:

                    hash_fields = dict(r.INFO)
                    hash_fields.update(dict(zip(r.samples[0].data._fields, r.samples[0].data)))

                    # We only analyse STR markers >=3 length
                    if len(str(hash_fields.get('RU', 0))) >= 3:
                        gene = str(hash_fields.get('REPID', ""))

                        # we retrieve all the info contained in the INFO fields

                        if hash_table.has_key((twin1_name, twin2_name, gene)):
                            hash_table[(twin1_name, twin2_name, gene)]['t2_alt1'] = str(hash_fields.get('REPCN', 0)).split('/')[0]
                            hash_table[(twin1_name, twin2_name, gene)]['t2_alt2'] = str(hash_fields.get('REPCN', 0)).split('/')[1]
                            hash_table[(twin1_name, twin2_name, gene)]['t2_name'] = twin2_name

                        else:
                            # we retrieve all the info contained in the INFO fields
                            hash_variant = {}

                            hash_variant['t2_alt1'] = str(hash_fields.get('REPCN', 0)).split('/')[0]
                            hash_variant['t2_alt2'] = str(hash_fields.get('REPCN', 0)).split('/')[1]
                            hash_variant['t2_name'] = twin2_name
                            hash_variant['gene'] = gene
                            hash_variant['t1_alt1'] = '0'
                            hash_variant['t1_alt2'] = '0'
                            hash_variant['t1_name'] = twin1_name
                            hash_table[(twin1_name, twin2_name, gene)] = hash_variant

                except:

                    raise RuntimeError(
                        'analysing_VCFs: Some error has occurred in variant line')

            # We enrich the information we have computing the differences in repeat-size between both twins
            for key2 in hash_table:

                if hash_table.get(key2)['t1_alt1'] is not None:
                    t1_alt1 = int(hash_table.get(key2)['t1_alt1'])
                else:
                    t1_alt1 = 0

                if hash_table.get(key2)['t2_alt1'] is not None:
                    t2_alt1 = int(hash_table.get(key2)['t2_alt1'])
                else:
                    t2_alt1 = 0

                diff_a1 = abs(t1_alt1 - t2_alt1)

                if hash_table.get(key2)['t1_alt2'] is not None:
                    t1_alt2 = int(hash_table.get(key2)['t1_alt2'])
                else:
                    t1_alt2 = 0

                if hash_table.get(key2)['t2_alt2'] is not None:
                    t2_alt2 = int(hash_table.get(key2)['t2_alt2'])
                else:
                    t2_alt2 = 0

                diff_a2 = abs(t1_alt2 - t2_alt2)

                hash_table[key2]['diff_a1'] = str(diff_a1)
                hash_table[key2]['diff_a2'] = str(diff_a2)

    return hash_table


def run(argv=None):

    if argv is None: argv = sys.argv

    parser = OptionParser(add_help_option=True, description="")
    parser.add_option("--f", default=None, help="The path to the TSV file containing the list of twins",
                      dest="f_twins")
    parser.add_option("--d", default=None, help="Directory or folder where the EH VCF output files are located",
                      dest="d_twins")
    parser.add_option("--o", default=None, help="The output TSV name in which the output comparison will be written",
                      dest="f_output")
    parser.add_option("--O", default=None, help="The output directory in which the output TSV file will be written",
                      dest="d_output")
    (options, args) = parser.parse_args(argv[1:])

    if len(argv) == 1:
        sys.exit(0)

    if not parser.check_required("--f"):
        raise IOError('The path to the TSV file containing the list of twins is missing')

    if not parser.check_required("--d"):
        raise IOError('The folder containing EH VCF output files is missing')

    if not parser.check_required("--o"):
        raise IOError('The output TSV name is missing')

    if not parser.check_required("--O"):
        raise IOError('The output directory in which the output TSV file will be written is missing')

    try:

        if options.f_twins is not None:

            f_twins = options.f_twins

            if not os.path.exists(f_twins):
                raise IOError('The path to the TSV file containing the list of twins %s does not exist') % f_twins

            dir_samples = options.d_twins

            if not os.path.exists(dir_samples):
                raise IOError('The directory where the VCF files from EH should be does not exist') % dir_samples

            output_folder = options.d_output

            if not os.path.exists(output_folder):
                os.mkdir(output_folder)

            output_tsv = options.f_output

            if output_tsv is None:
                raise IOError('The name for the output TSV file is missing %s') % output_tsv

            output_file = os.path.join(output_folder, output_tsv)

            formatter = logging.Formatter('%(asctime)s - %(module)s - %(levelname)s - %(message)s')
            console = logging.StreamHandler()
            console.setFormatter(formatter)
            console.setLevel(logging.INFO)
            logger = logging.getLogger("preprocess")
            logger.setLevel(logging.INFO)
            logger.addHandler(console)


            hash_twins = read_tsv_file(f_twins)

            logger.info("The analysis of assessing repeat-sizes in twins has started")

            # list of all EH VCF files existing in the directory/folder
            l_vcf = [f for f in os.listdir(dir_samples) if f.endswith('.vcf')]

            l_samples = []

            for vcf in l_vcf:
                sample_name = re.sub('^EH_', '', vcf)
                sample_name = re.sub('.vcf$', '', sample_name)
                l_samples.append(sample_name)

            hash_table = analysing_VCFs(hash_twins, l_samples, dir_samples, logger)

            tsv_file = print_tables(hash_table, output_file)

            logger.info(
                "The merged VCF files has been annotated and enriched. Take a look to the TSV file %s") % tsv_file

    except:
        print >> sys.stderr, '\n%s\t%s' % (sys.exc_info()[0], sys.exc_info()[1])
        sys.exit(2)


########################################################################################################################

if __name__ == '__main__':
    run()

