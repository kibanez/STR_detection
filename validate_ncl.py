'''
Created on 29-06-2017

@author: kristina ibanez-garikano
'''

# !/usr/bin/python

import sys, os, re, math

import pandas as pd

import numpy as np

import optparse

import logging

import vcf

######################################################################

class OptionParser(optparse.OptionParser):
    def check_required(self, opt):

        option = self.get_option(opt)

        atrib = getattr(self.values, option.dest)

        if atrib is None:
            #            self.error("%s option not supplied" % option)
            return False
        else:
            return True

############################################################################################################################################
# Function that prints two tsv files: one containing all the allelotype-lobSTR VCF, already enriched somehow
# and the other table, containing only the STR loci that are spotted by having more repetitions that teoretically
# and in practice have been seen

def print_tables(hash_table, f_output):

    l_fields = ['dna_id', 'lp_id', 'validation_a1', 'validation_a2', 'eh_a1', 'eh_a2', 'diff_a1', 'diff_a2', 'typeReads_a1', 'typeReads_a2', 'numReads_a1',
                'numReads_a2', 'sizeRepeat_a1', 'sizeRepeat_a2']

    fo = open(f_output, 'w')
    fo.write('\t'.join(l_fields) + '\n')
    for key in sorted(hash_table.keys()):
        fo.write('\t'.join(map(lambda field: hash_table[key].get(field, '.'), l_fields)) + '\n')
    fo.close()

    return f_output


############################################################################################################################################
# Function that reads the experimental validation TSV file and creates a hash table containing the information
# corresponding to the both alleles-repeat sizes + LP id (derived from the hash_dna2lp

def read_validation_tsv(tsv_file, hash_dna2lp):
    data = pd.read_csv(tsv_file, sep='\t', error_bad_lines=False)

    # output file with the DNA id's without any match
    output_not_matching_dna = tsv_file.split('.tsv')[0] + '_not_matching_DNA.tsv'

    l_dna = data.iloc[:, 0].tolist()
    l_allele1 = data.iloc[:, 1].tolist()
    l_allele2 = data.iloc[:, 2].tolist()

    # Create a LP-ID list that makes correspondence with the NHNN-DNA id's

    l_lp = []
    l_dna_without_match = []

    for i in l_dna:

        if hash_dna2lp.has_key(str(i)):

            if isinstance(hash_dna2lp.get(str(i)), float):
                l_dna_without_match.append(i)
            else:
                lp_id = str(hash_dna2lp.get(str(i)))
                l_lp.append(lp_id)
        else:
            l_dna_without_match.append(i)

    hash_allele1 = dict(zip(l_lp, l_allele1))
    hash_allele2 = dict(zip(l_lp, l_allele2))

    # Write the list of not matching DNA with NCL-LPs into a file
    fo = open(output_not_matching_dna, 'w')
    fo.write('\n'.join(l_dna_without_match))
    fo.close()

    return hash_allele1, hash_allele2

############################################################################################################################################
# Function that reads the TSV file containing the correspondence ID's between the NHNN institute and the GEL ids
# It creates a hash table with keys: dna-NHNN and value: LP-GEL

def read_identification_tsv(dna2lp_file):

    data = pd.read_csv(dna2lp_file, sep='\t', header = None)

    l_dna = data.iloc[:, 0].tolist()
    l_lp = data.iloc[:, 1].tolist()

    hash_table = dict(zip(l_dna, l_lp))
    #hash_table2 = dict(zip(l_lp, l_dna))

    # we exchange key-value values
    hash_table2 = dict((value, key) for key, value in hash_table.iteritems())

    return hash_table, hash_table2

############################################################################################################################################
# Function that takes the LP id for each participant validated experimentally (given in the TSV validation data)
# and extract from the VCF generated by EH the alleles repeat-sizes that it estimates
# It creates a bigger hash table containing the DNA-NHNN, GEL-LP-ID, validation allele 1 , validation allele 2, eh allele 1, and eh allele2

def extracting_eh_estimations(hash_lp2dna, hash_allele1, hash_allele2, locus, vcf_path, logger):

    #vcf_path = '/Users/kibanez/Documents/GEL_STR/EH-offtarget-reads/HA/EH-offtarget_output_specs_Jan2017/merging_VCF'

    #vcf_path = '/Users/kibanez/Documents//GEL_STR/EH-offtarget-reads/panels_STR/EH-offtarget_output_specs_Jan2017'

    #vcf_path = '/Users/kibanez/Documents/GEL_STR/Validation-NCL-AND-NHNN/Pilot_EH_v2.5.3'

    if not os.path.exists(vcf_path):
        raise IOError('The corresponding path where the VCF files generated by EH are does not exist %s' %vcf_path)

    logger.info('NOTE: The VCF files that we are examining are located in %s' %vcf_path)

    hash_table = {}
    for key, value in hash_allele1.items():

        lp_id = key
        dna_id = hash_lp2dna.get(lp_id, ".")

        logger.info("Extracting information from ... %s" %(lp_id))

        if ((lp_id == '.') and (dna_id == '.')) or isinstance(dna_id, float):
            continue

        if lp_id is not None:

            vcf_name = 'EH_' + lp_id + '.vcf'
            # if there is no LP correspondence with the DNA-id, we will write . in the table
            if lp_id == '.':

                hash_variant = {}
                hash_variant['lp_id'] = "No LP id associated"
                hash_variant['dna_id'] = dna_id
                hash_variant['validation_a1'] = "."
                hash_variant['validation_a2'] = "."
                hash_variant['eh_a1'] = "."
                hash_variant['eh_a2'] = "."
                hash_variant['diff_a1'] = "."
                hash_variant['diff_a2'] = "."
                hash_variant['typeReads_a1'] = "."
                hash_variant['typeReads_a2'] = "."
                hash_variant['numReads_a1'] = "."
                hash_variant['numReads_a2'] = "."
                hash_variant['sizeRepeat_a1'] = "."
                hash_variant['sizeRepeat_a2'] = "."

                hash_table[(lp_id, dna_id)] = hash_variant
                continue

            vcf_file = os.path.join(vcf_path, vcf_name)

            if not os.path.exists(vcf_file):
                #raise IOError('The VCF estimated by EH %s does not exist' %vcf_file)

                hash_variant = {}
                hash_variant['lp_id'] = lp_id + ' not_sequenced'
                hash_variant['dna_id'] = dna_id
                hash_variant['validation_a1'] = "."
                hash_variant['validation_a2'] = "."
                hash_variant['eh_a1'] = "."
                hash_variant['eh_a2'] = "."
                hash_variant['diff_a1'] = "."
                hash_variant['diff_a2'] = "."
                hash_variant['typeReads_a1'] = "."
                hash_variant['typeReads_a2'] = "."
                hash_variant['numReads_a1'] = "."
                hash_variant['numReads_a2'] = "."
                hash_variant['sizeRepeat_a1'] = "."
                hash_variant['sizeRepeat_a2'] = "."

                hash_table[(lp_id, dna_id)] = hash_variant
                continue


            # Read or extract the repeat sizes from the VCF file
            vcf_reader = vcf.Reader(filename=vcf_file)

            for i, r in enumerate(vcf_reader):

                info = r.INFO
                l_s = r.samples  # samples of each vcf

                try:

                    gene = info['REPID']

                    # We only want to extract info from the GENE/LOCUS that the user enters
                    # D&C: we don't want to analyse all the alleles and positions, only those positions or locus we are interested in
                    if gene == locus:

                        # alt contains the repeat-size if there is an allele(s) with different repeat size than the reference
                        alt = r.ALT

                        if isinstance(alt, list):
                            l_alt_clean = []
                            # <STR18>,<STR23> <-- these 2 numbers would be the
                            # .  <-- this also can be there, as [None]

                            if alt == [None]:

                                l_alt_clean.append(str(info['REF']))

                            else:

                                for j in alt:

                                    alt_ind = str(j)
                                    alt_number = re.sub('^<', '', alt_ind)
                                    alt_number = re.sub('>$', '', alt_number)
                                    alt_number = re.sub('^STR', '', alt_number)
                                    l_alt_clean.append(alt_number)

                        else:

                            # l_alt_clean will be composed for 1 alternative allele
                            l_alt_clean = []
                            # <STR18>
                            alt_number = re.sub('^<', '', str(alt[0]))
                            alt_number = re.sub('>$', '', alt_number)
                            alt_number = re.sub('^STR', '', alt_number)
                            l_alt_clean.append(alt_number)

                        for sample in l_s:

                            # GT:SO:SP:CN:CI	1/2:SPANNING/SPANNING:13/8:17/22:./.
                            # SO: spanning/spanning
                            # SP: number of alleles supporting each repeat-size
                            # CN: the repeat-sizes (ref and alt)

                            if sample['GT'] == "":
                                sample_GT = '.'
                            else:
                                sample_GT = sample['GT']

                            if sample['SO'] is None:
                                sample_SO = '.'
                            else:
                                sample_SO = sample['SO'].split('/')

                            if sample['ADSP'] is None:
                                sample_SP = '.'
                            else:
                                sample_SP = sample['ADSP'].split('/')

                            if sample['ADFL'] is None:
                                sample_FL = '.'
                            else:
                                sample_FL = sample['ADFL'].split('/')

                            if sample['ADIR'] is None:
                                sample_IR = '.'
                            else:
                                sample_IR = sample['ADIR'].split('/')

                            if sample['REPCN'] is None:
                                sample_CN = '.'
                            else:
                                sample_CN = sample['REPCN'].split('/')

                            # if any sample_* is not a list, this means that the GT is '0' or '1' and we have to create a list of it
                            if len(sample_SO) == 1:
                                aux = str(sample_SO[0])
                                sample_SO = []
                                sample_SO.append(aux)
                                sample_SO.append(aux)

                            if len(sample_SP) == 1:
                                aux = str(sample_SP[0])
                                sample_SP = []
                                sample_SP.append(aux)
                                sample_SP.append(aux)

                            if len(sample_FL) == 1:
                                aux = str(sample_FL[0])
                                sample_FL = []
                                sample_FL.append(aux)
                                sample_FL.append(aux)

                            if len(sample_IR) == 1:
                                aux = str(sample_IR[0])
                                sample_IR = []
                                sample_IR.append(aux)
                                sample_IR.append(aux)

                            if len(sample_CN) == 1:
                                aux = str(sample_CN[0])
                                sample_CN = []
                                sample_CN.append(aux)
                                sample_CN.append(aux)

                            sample_ref = info['REF']

                            # if GT=0 (0/0) allele1 = allele2 = REF (INFO REF field)
                            if sample_GT == '0/0':
                                eh_allele1 = str(sample_ref)
                                eh_allele2 = str(sample_ref)

                            elif sample_GT == '1/1':
                                if len(l_alt_clean) > 1:
                                    eh_allele1 = str(l_alt_clean[0])
                                    eh_allele2 = str(l_alt_clean[1])
                                else:
                                    eh_allele1 = str(l_alt_clean[0])
                                    eh_allele2 = str(l_alt_clean[0])

                            elif sample_GT == '1/2':
                                if len(l_alt_clean) > 1:
                                    eh_allele1 = l_alt_clean[0]
                                    eh_allele2 = l_alt_clean[1]
                                else:
                                    print 'Ey, take a look what is happening here.'
                            elif sample_GT == '0/1':
                                eh_allele1 = str(sample_ref)
                                eh_allele2 = str(l_alt_clean[0])
                            elif sample_GT == '0/1/2':
                                eh_allele1 = str(sample_ref)
                                eh_allele2 = str(max(int(l_alt_clean[0]), int(l_alt_clean[1])))
                            elif sample_GT == '.':
                                if sample_SP == '.':
                                    eh_allele1 = str(sample_ref)
                                    eh_allele2 = str(sample_ref)
                                else:
                                    logger.info("Something weird is happening in this VCF file %s" %(lp_id))
                            else:
                                if len(l_alt_clean) == 2:

                                    eh_allele1 = l_alt_clean[0]
                                    eh_allele2 = l_alt_clean[1]

                                else:

                                    #we take the 2 alleles with the max number of reads supporting the repeat-size estimated by EH
                                    aux_sample_SP = map(int, sample_SP)
                                    index_max1 = np.argmax(aux_sample_SP)
                                    eh_allele2 = sample_CN[index_max1]

                                    # we put to 0 the maximum number, so as to check the next max value
                                    aux_sample_SP[index_max1] = 0

                                    index_max2 = np.argmax(aux_sample_SP)
                                    eh_allele1 = sample_CN[index_max2]

                        # include in the hash_table
                        hash_variant = {}
                        hash_variant['lp_id'] = lp_id
                        hash_variant['dna_id'] = dna_id
                        hash_variant['validation_a1'] = str(hash_allele1.get(lp_id, "."))
                        hash_variant['validation_a2'] = str(hash_allele2.get(lp_id, "."))
                        hash_variant['eh_a1'] = eh_allele1
                        hash_variant['eh_a2'] = eh_allele2


                        if hash_allele1.get(lp_id, ".") != '#VALUE!' and hash_allele2.get(lp_id, ".") != '.':
                            hash_variant['diff_a1'] = str(abs(float(hash_allele1.get(lp_id)) - float(eh_allele1)))
                        else:
                            hash_variant['diff_a1'] = "."

                        if hash_allele2.get(lp_id, ".") != '#VALUE!' and hash_allele2.get(lp_id, ".") != '.':
                            hash_variant['diff_a2'] = str(abs(float(hash_allele2.get(lp_id)) - float(eh_allele2)))
                        else:
                            hash_variant['diff_a2'] = "."

                        # we need to assign the number of reads, type of reads and the size repeat for each allele
                        # It would be easy if we would have only max of 2 alleles, but EH sometimes estimates more than 2...
                        # Strategy adopted: select 2 alleles with the max number of reads estimating the repeat-size
                        if len(sample_SO) > 2:

                            aux_sample_SP = map(int, sample_SP)
                            index_max1 = np.argmax(aux_sample_SP)
                            max1 = sample_SP[index_max1]

                            # we put to 0 the maximum number, so as to check the next max value
                            aux_sample_SP[index_max1] = 0

                            index_max2 = np.argmax(aux_sample_SP)
                            max2 = sample_SP[index_max2]

                            hash_variant['numReads_a1'] = max2
                            hash_variant['numReads_a2'] = max1
                            hash_variant['typeReads_a1'] = sample_SO[index_max2]
                            hash_variant['typeReads_a2'] = sample_SO[index_max1]
                            hash_variant['sizeRepeat_a1'] = sample_CN[index_max2]
                            hash_variant['sizeRepeat_a2'] = sample_CN[index_max1]

                        else:

                            hash_variant['typeReads_a1'] = sample_SO[0]
                            hash_variant['typeReads_a2'] = sample_SO[1]
                            hash_variant['numReads_a1'] = sample_SP[0]
                            hash_variant['numReads_a2'] = sample_SP[1]
                            hash_variant['sizeRepeat_a1'] = sample_CN[0]
                            hash_variant['sizeRepeat_a2'] = sample_CN[1]

                        hash_table[(lp_id, dna_id)] = hash_variant


                except:

                    raise RuntimeError(
                        'validate_nhnn.extracting_eh_estimations: Some error has occurred in variant line')

    return hash_table

############################################################################################################################################

def run(argv=None):

    if argv is None: argv = sys.argv

    parser = OptionParser(add_help_option=True, description="")

    parser.add_option("--tsv", default=None,
                      help="TSV file containing the experimental validation corresponding to a locus/gene",
                      dest="f_tsv")

    parser.add_option("--dna2lp", default=None,
                      help="TSV file containing the correspondence between the DNA-id from NHNN and the LP id's from GEL",
                      dest="f_dna2lp")

    parser.add_option("--locus", default=None,
                      help="The locus or gene that we want to validate (i.e., FMR1)",
                      dest="locus")

    parser.add_option("--EH_output", default=None,
                      help="The folder where EH output are located (vcf, json and log files)",
                      dest="eh_output")

    parser.add_option("--o", default=None,
                      help="The name of the output TSV file in which the result will be written",
                      dest="f_output")

    (options, args) = parser.parse_args(argv[1:])

    if len(argv) == 1:
        sys.exit(0)

    if not parser.check_required("--tsv"):
        raise IOError('The TSV file containing the experimental validation does not exist, please provide it')

    if not parser.check_required("--dna2lp"):
        raise IOError('The TSV file containing the correspondce between the DNA-id from NHNN and LP ids from GEL does not exist. Please, look for a file called as dna-nhnn_to_LP-GEL.tsv')

    if not parser.check_required("--locus"):
        raise IOError('The locus to be validated is missing. Please provide it, along with the TSV files')

    if not parser.check_required("--EH_output"):
        raise IOError('The folder containing EH output files is missing. We cannot compare estimations!')

    if not parser.check_required("--o"):
        raise IOError('The output file in which the results will be written is missing. Please, provide it')

    try:

        if options.f_tsv is not None:

            dna2lp_file = options.f_dna2lp

            if not os.path.exists(dna2lp_file):
                raise IOError('The TSV file including the correspondence NCL-IDs and GEL-IDs does not exist %s' %(dna2lp_file))

            tsv_file = options.f_tsv

            if not os.path.exists(tsv_file):
                raise IOError('The TSV file including the experimental validation %s does not exist' % (tsv_file))

            locus = options.locus

            if locus is None:
                raise IOError('A gene name must be given, in order to proceed with the validation')

            vcf_path = options.eh_output

            if not os.path.exists(vcf_path):
                raise IOError('The folder containing EH output files does not exist %s' % vcf_path)

            output_file = options.f_output

            if output_file is None:
                raise IOError('The path to the output file is missing %s. Please, provide it.' %output_file)

            # Configure logger
            formatter = logging.Formatter('%(asctime)s - %(module)s - %(levelname)s - %(message)s')
            console = logging.StreamHandler()
            console.setFormatter(formatter)
            console.setLevel(logging.INFO)
            logger = logging.getLogger("preprocess")
            logger.setLevel(logging.INFO)
            logger.addHandler(console)

            logger.info("Comparing the experimental validation results coming from NCL with the EH from GEL...")

            logger.info("Reading the NCL-GEL ids correspondence file...")

            hash_dna2lp, hash_lp2dna = read_identification_tsv(dna2lp_file)

            logger.info("Reading the NCL-GEL ids correspondence file...")

            hash_allele1, hash_allele2 = read_validation_tsv(tsv_file, hash_dna2lp)

            logger.info("Extracting the EH estimated repeat sizes for each allele...")

            hash_eh = extracting_eh_estimations(hash_lp2dna, hash_allele1, hash_allele2, locus, vcf_path, logger)

            print_tables(hash_eh, output_file)

            logger.info("...the comparison finished!")

            logger.info("Check the output file: %s" %output_file)

    except:

        print >> sys.stderr, '\n%s\t%s' % (sys.exc_info()[0], sys.exc_info()[1])
        sys.exit(2)


############################################################################333

if __name__ == '__main__':
    run()

