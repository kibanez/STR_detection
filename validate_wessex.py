'''
Created on 16-10-2018

@author: kristina ibanez-garikano
'''

# !/usr/bin/python
import sys, os, re, optparse, logging, vcf
import pandas as pd
import numpy as np

class OptionParser(optparse.OptionParser):
    def check_required(self, opt):

        option = self.get_option(opt)

        atrib = getattr(self.values, option.dest)

        if atrib is None:
            #            self.error("%s option not supplied" % option)
            return False
        else:
            return True


def print_tables(hash_table, f_output):
    '''
    Function that prints two tsv files: one containing all the allelotype-lobSTR VCF, already enriched somehow
    and the other table, containing only the STR loci that are spotted by having more repetitions that teoretically
    and in practice have been seen

    :param hash_table: keys are platekeys and then we do have the repeat-sizes corresponding to experimental
    and EH repeat-sizes, together with other information
    :param f_output: output file where it will be printed the information
    :return:
    '''

    l_fields = ['lp_id', 'validation_a1', 'validation_a2', 'eh_a1', 'eh_a2', 'diff_a1', 'diff_a2', 'typeReads_a1',
                'typeReads_a2', 'numReads_a1', 'numReads_a2', 'sizeRepeat_a1', 'sizeRepeat_a2']

    fo = open(f_output, 'w')
    fo.write('\t'.join(l_fields) + '\n')
    for key in sorted(hash_table.keys()):
        fo.write('\t'.join(map(lambda field: hash_table[key].get(field, '.'), l_fields)) + '\n')
    fo.close()

    return f_output


def read_validation_tsv(tsv_file):
    '''
     Function that reads the experimental validation TSV file and creates a hash table containing the information
    corresponding to the both alleles-repeat sizes + LP id

    :param tsv_file:
    :param hash_dna2lp:
    :return:
    '''

    data = pd.read_csv(tsv_file, sep='\t', error_bad_lines=False)

    # output file with the DNA id's without any match
    output_not_matching_dna = tsv_file.split('.tsv')[0] + '_not_matching_DNA.tsv'

    l_lp = data.iloc[:, 0].tolist()
    l_allele1 = data.iloc[:, 1].tolist()
    l_allele2 = data.iloc[:, 2].tolist()
    hash_allele1 = dict(zip(l_lp, l_allele1))
    hash_allele2 = dict(zip(l_lp, l_allele2))

    return hash_allele1, hash_allele2


def extracting_eh_estimations(hash_allele1, hash_allele2, locus, vcf_path, logger):
    '''
    Function that takes the LP id for each participant validated experimentally (given in the TSV validation data)
    and extract from the VCF generated by EH the alleles repeat-sizes that it estimates
    It creates a bigger hash table containing the DNA-NHNN, GEL-LP-ID, validation allele 1 , validation allele 2, eh allele 1, and eh allele2

    :param hash_allele1: experimental validation for allele 1
    :param hash_allele2: experimental validation for allele 2
    :param locus: the gene we are analysing STRs
    :param vcf_path: path to the EH output VCF file
    :param logger: logger
    :return:
    '''

    if not os.path.exists(vcf_path):
        raise IOError('The corresponding path where the VCF files generated by EH are does not exist %s' % vcf_path)

    logger.info('NOTE: The VCF files that we are examining are located in %s' % vcf_path)

    hash_table = {}
    for key, value in hash_allele1.items():

        lp_id = key

        logger.info("Extracting information from ... %s" % lp_id)

        if lp_id is not None:

            vcf_name = 'EH_' + lp_id + '.vcf'
            # if there is no LP correspondence with the DNA-id, we will write . in the table
            if lp_id == '.':

                hash_variant = {}
                hash_variant['lp_id'] = "No LP id associated"
                hash_variant['dna_id'] = dna_id
                hash_variant['validation_a1'] = "."
                hash_variant['validation_a2'] = "."
                hash_variant['eh_a1'] = "."
                hash_variant['eh_a2'] = "."
                hash_variant['diff_a1'] = "."
                hash_variant['diff_a2'] = "."
                hash_variant['typeReads_a1'] = "."
                hash_variant['typeReads_a2'] = "."
                hash_variant['numReads_a1'] = "."
                hash_variant['numReads_a2'] = "."
                hash_variant['sizeRepeat_a1'] = "."
                hash_variant['sizeRepeat_a2'] = "."

                hash_table[lp_id] = hash_variant
                continue

            vcf_file = os.path.join(vcf_path, vcf_name)

            if not os.path.exists(vcf_file):
                #raise IOError('The VCF estimated by EH %s does not exist' %vcf_file)

                hash_variant = {}
                hash_variant['lp_id'] = lp_id + ' not_sequenced'
                hash_variant['validation_a1'] = "."
                hash_variant['validation_a2'] = "."
                hash_variant['eh_a1'] = "."
                hash_variant['eh_a2'] = "."
                hash_variant['diff_a1'] = "."
                hash_variant['diff_a2'] = "."
                hash_variant['typeReads_a1'] = "."
                hash_variant['typeReads_a2'] = "."
                hash_variant['numReads_a1'] = "."
                hash_variant['numReads_a2'] = "."
                hash_variant['sizeRepeat_a1'] = "."
                hash_variant['sizeRepeat_a2'] = "."

                hash_table[lp_id] = hash_variant
                continue

            vcf_reader = vcf.Reader(filename=vcf_file)

            for i, r in enumerate(vcf_reader):

                info = r.INFO
                l_s = r.samples  # samples of each vcf

                try:

                    gene = info['REPID']

                    # We only want to extract info from the GENE/LOCUS that the user enters
                    # D&C: we don't want to analyse all the alleles and positions, only those positions or locus we are interested in
                    if gene == locus:

                        # alt contains the repeat-size if there is an allele(s) with different repeat size than the reference
                        alt = r.ALT

                        if isinstance(alt, list):
                            l_alt_clean = []
                            # <STR18>,<STR23> <-- these 2 numbers would be the
                            # .  <-- this also can be there, as [None]

                            if alt == [None]:

                                l_alt_clean.append(str(info['REF']))

                            else:

                                for j in alt:

                                    alt_ind = str(j)
                                    alt_number = re.sub('^<', '', alt_ind)
                                    alt_number = re.sub('>$', '', alt_number)
                                    alt_number = re.sub('^STR', '', alt_number)
                                    l_alt_clean.append(alt_number)

                        else:

                            # l_alt_clean will be composed for 1 alternative allele
                            l_alt_clean = []
                            # <STR18>
                            alt_number = re.sub('^<', '', str(alt[0]))
                            alt_number = re.sub('>$', '', alt_number)
                            alt_number = re.sub('^STR', '', alt_number)
                            l_alt_clean.append(alt_number)

                        for sample in l_s:

                            # GT:SO:SP:CN:CI	1/2:SPANNING/SPANNING:13/8:17/22:./.
                            # SO: spanning/spanning
                            # SP: number of alleles supporting each repeat-size
                            # CN: the repeat-sizes (ref and alt)

                            if sample['GT'] == "":
                                sample_GT = '.'
                            else:
                                sample_GT = sample['GT']

                            if sample['SO'] is None:
                                sample_SO = '.'
                            else:
                                sample_SO = sample['SO'].split('/')

                            if sample['ADSP'] is None:
                                sample_SP = '.'
                            else:
                                sample_SP = sample['ADSP'].split('/')

                            if sample['ADFL'] is None:
                                sample_FL = '.'
                            else:
                                sample_FL = sample['ADFL'].split('/')

                            if sample['ADIR'] is None:
                                sample_IR = '.'
                            else:
                                sample_IR = sample['ADIR'].split('/')

                            if sample['REPCN'] is None:
                                sample_CN = '.'
                            else:
                                sample_CN = sample['REPCN'].split('/')

                            # if any sample_* is not a list, this means that the GT is '0' or '1' and we have to create a list of it
                            if len(sample_SO) == 1:
                                aux = str(sample_SO[0])
                                sample_SO = []
                                sample_SO.append(aux)
                                sample_SO.append(aux)

                            if len(sample_SP) == 1:
                                aux = str(sample_SP[0])
                                sample_SP = []
                                sample_SP.append(aux)
                                sample_SP.append(aux)

                            if len(sample_FL) == 1:
                                aux = str(sample_FL[0])
                                sample_FL = []
                                sample_FL.append(aux)
                                sample_FL.append(aux)

                            if len(sample_IR) == 1:
                                aux = str(sample_IR[0])
                                sample_IR = []
                                sample_IR.append(aux)
                                sample_IR.append(aux)

                            if len(sample_CN) == 1:
                                aux = str(sample_CN[0])
                                sample_CN = []
                                sample_CN.append(aux)
                                sample_CN.append(aux)

                            sample_ref = info['REF']

                            # if GT=0 (0/0) allele1 = allele2 = REF (INFO REF field)
                            if sample_GT == '0/0':
                                eh_allele1 = str(sample_ref)
                                eh_allele2 = str(sample_ref)

                            elif sample_GT == '1/1':
                                if len(l_alt_clean) > 1:
                                    eh_allele1 = str(l_alt_clean[0])
                                    eh_allele2 = str(l_alt_clean[1])
                                else:
                                    eh_allele1 = str(l_alt_clean[0])
                                    eh_allele2 = str(l_alt_clean[0])

                            elif sample_GT == '1/2':
                                if len(l_alt_clean) > 1:
                                    eh_allele1 = l_alt_clean[0]
                                    eh_allele2 = l_alt_clean[1]
                                else:
                                    print 'Ey, take a look what is happening here.'
                            elif sample_GT == '0/1':
                                eh_allele1 = str(sample_ref)
                                eh_allele2 = str(l_alt_clean[0])
                            elif sample_GT == '0/1/2':
                                eh_allele1 = str(sample_ref)
                                eh_allele2 = str(max(int(l_alt_clean[0]), int(l_alt_clean[1])))
                            elif sample_GT == '.':
                                if sample_SP == '.':
                                    eh_allele1 = str(sample_ref)
                                    eh_allele2 = str(sample_ref)
                                else:
                                    logger.info("Something weird is happening in this VCF file %s" %(lp_id))
                            else:
                                if len(l_alt_clean) == 2:

                                    eh_allele1 = l_alt_clean[0]
                                    eh_allele2 = l_alt_clean[1]

                                else:

                                    #we take the 2 alleles with the max number of reads supporting the repeat-size estimated by EH
                                    aux_sample_SP = map(int, sample_SP)
                                    index_max1 = np.argmax(aux_sample_SP)
                                    eh_allele2 = sample_CN[index_max1]

                                    # we put to 0 the maximum number, so as to check the next max value
                                    aux_sample_SP[index_max1] = 0

                                    index_max2 = np.argmax(aux_sample_SP)
                                    eh_allele1 = sample_CN[index_max2]

                        # include in the hash_table
                        hash_variant = {}
                        hash_variant['lp_id'] = lp_id
                        hash_variant['validation_a1'] = str(hash_allele1.get(lp_id, "."))
                        hash_variant['validation_a2'] = str(hash_allele2.get(lp_id, "."))
                        hash_variant['eh_a1'] = eh_allele1
                        hash_variant['eh_a2'] = eh_allele2


                        if hash_allele1.get(lp_id, ".") != '#VALUE!' and hash_allele2.get(lp_id, ".") != '.':
                            hash_variant['diff_a1'] = str(abs(float(hash_allele1.get(lp_id)) - float(eh_allele1)))
                        else:
                            hash_variant['diff_a1'] = "."

                        if hash_allele2.get(lp_id, ".") != '#VALUE!' and hash_allele2.get(lp_id, ".") != '.':
                            hash_variant['diff_a2'] = str(abs(float(hash_allele2.get(lp_id)) - float(eh_allele2)))
                        else:
                            hash_variant['diff_a2'] = "."

                        # we need to assign the number of reads, type of reads and the size repeat for each allele
                        # It would be easy if we would have only max of 2 alleles, but EH sometimes estimates more than 2...
                        # Strategy adopted: select 2 alleles with the max number of reads estimating the repeat-size
                        if len(sample_SO) > 2:

                            aux_sample_SP = map(int, sample_SP)
                            index_max1 = np.argmax(aux_sample_SP)
                            max1 = sample_SP[index_max1]

                            # we put to 0 the maximum number, so as to check the next max value
                            aux_sample_SP[index_max1] = 0

                            index_max2 = np.argmax(aux_sample_SP)
                            max2 = sample_SP[index_max2]

                            hash_variant['numReads_a1'] = max2
                            hash_variant['numReads_a2'] = max1
                            hash_variant['typeReads_a1'] = sample_SO[index_max2]
                            hash_variant['typeReads_a2'] = sample_SO[index_max1]
                            hash_variant['sizeRepeat_a1'] = sample_CN[index_max2]
                            hash_variant['sizeRepeat_a2'] = sample_CN[index_max1]

                        else:

                            hash_variant['typeReads_a1'] = sample_SO[0]
                            hash_variant['typeReads_a2'] = sample_SO[1]
                            hash_variant['numReads_a1'] = sample_SP[0]
                            hash_variant['numReads_a2'] = sample_SP[1]
                            hash_variant['sizeRepeat_a1'] = sample_CN[0]
                            hash_variant['sizeRepeat_a2'] = sample_CN[1]

                        hash_table[lp_id] = hash_variant


                except:

                    raise RuntimeError(
                        'validate_wessex.extracting_eh_estimations: Some error has occurred in variant line')

    return hash_table


def run(argv=None):

    if argv is None: argv = sys.argv

    parser = OptionParser(add_help_option=True, description="")

    parser.add_option("--tsv", default=None,
                      help="TSV file containing the experimental validation corresponding to a locus/gene",
                      dest="f_tsv")

    parser.add_option("--locus", default=None,
                      help="The locus or gene that we want to validate (i.e., FMR1)",
                      dest="locus")

    parser.add_option("--EH_output", default=None,
                      help="The folder where EH output are located (vcf, json and log files)",
                      dest="eh_output")

    parser.add_option("--o", default=None,
                      help="The name of the output TSV file in which the result will be written",
                      dest="f_output")

    (options, args) = parser.parse_args(argv[1:])

    if len(argv) == 1:
        sys.exit(0)

    if not parser.check_required("--tsv"):
        raise IOError('The TSV file containing the experimental validation does not exist, please provide it')

    if not parser.check_required("--locus"):
        raise IOError('The locus to be validated is missing. Please provide it, along with the TSV files')

    if not parser.check_required("--EH_output"):
        raise IOError('The folder containing EH output files is missing. We cannot compare estimations!')

    if not parser.check_required("--o"):
        raise IOError('The output file in which the results will be written is missing. Please, provide it')

    try:

        if options.f_tsv is not None:

            tsv_file = options.f_tsv

            if not os.path.exists(tsv_file):
                raise IOError('The TSV file including the experimental validation %s does not exist' % tsv_file)

            locus = options.locus

            if locus is None:
                raise IOError('A gene name must be given, in order to proceed with the validation')

            vcf_path = options.eh_output

            if not os.path.exists(vcf_path):
                raise IOError('The folder containing EH output files does not exist %s' % vcf_path)

            output_file = options.f_output

            if output_file is None:
                raise IOError('The path to the output file is missing %s. Please, provide it.' % output_file)

            # Configure logger
            formatter = logging.Formatter('%(asctime)s - %(module)s - %(levelname)s - %(message)s')
            console = logging.StreamHandler()
            console.setFormatter(formatter)
            console.setLevel(logging.INFO)
            logger = logging.getLogger("preprocess")
            logger.setLevel(logging.INFO)
            logger.addHandler(console)

            logger.info("Comparing the experimental validation results coming from NCL with the EH from GEL...")

            logger.info("Reading the Wessex validation values file...")

            hash_allele1, hash_allele2 = read_validation_tsv(tsv_file)

            logger.info("Extracting the EH estimated repeat sizes for each allele...")

            hash_eh = extracting_eh_estimations(hash_allele1, hash_allele2, locus, vcf_path, logger)

            print_tables(hash_eh, output_file)

            logger.info("...the comparison finished!")

            logger.info("Check the output file: %s" % output_file)

    except:

        print >> sys.stderr, '\n%s\t%s' % (sys.exc_info()[0], sys.exc_info()[1])
        sys.exit(2)

if __name__ == '__main__':
    run()

